{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91ca4ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-20 18:18:45.037 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run D:\\Programs\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import cv2\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# Lets try to integrate streamlit and mediapipe\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils  # Drawing helpers\n",
    "mp_holistic = mp.solutions.holistic\n",
    "\n",
    "DEMO_VIDEO = 'D:\\\\Face-Mesh-MediaPipe\\\\Demos\\\\bella porch to demo.mp4'\n",
    "\n",
    "st.title('Movement Detection Application using MediaPipe')\n",
    "\n",
    "st.markdown(\n",
    "    \"\"\"\n",
    "    <style>\n",
    "    [data-testid=\"stSidebar\"][aria-expanded=\"true\"] > div:first-child {\n",
    "        width: 350px;\n",
    "    }\n",
    "    [data-testid=\"stSidebar\"][aria-expanded=\"false\"] > div:first-child {\n",
    "        width: 350px;\n",
    "        margin-left: -350px;\n",
    "    }\n",
    "    </style>\n",
    "    \"\"\",\n",
    "    unsafe_allow_html=True,\n",
    ")\n",
    "\n",
    "st.sidebar.title('Movement Detection Application using MediaPipe')\n",
    "st.sidebar.subheader('Parameters')\n",
    "\n",
    "\n",
    "@st.cache()\n",
    "def image_resize(image, width=None, height=None, inter=cv2.INTER_AREA):\n",
    "    # initialize the dimensions of the image to be resized and\n",
    "    # grab the image size\n",
    "    dim = None\n",
    "    (h, w) = image.shape[:2]\n",
    "\n",
    "    # if both the width and height are None, then return the\n",
    "    # original image\n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "\n",
    "    # check to see if the width is None\n",
    "    if width is None:\n",
    "        # calculate the ratio of the height and construct the\n",
    "        # dimensions\n",
    "        r = height / float(h)\n",
    "        dim = (int(w * r), height)\n",
    "\n",
    "    # otherwise, the height is None\n",
    "    else:\n",
    "        # calculate the ratio of the width and construct the\n",
    "        # dimensions\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h * r))\n",
    "\n",
    "    # resize the image\n",
    "    resized = cv2.resize(image, dim, interpolation=inter)\n",
    "\n",
    "    # return the resized image\n",
    "    return resized\n",
    "\n",
    "\n",
    "app_mode = st.sidebar.selectbox('Choose the App mode',\n",
    "                                ['About App', 'Run on Video', 'Dataset']\n",
    "                                )\n",
    "\n",
    "if app_mode == 'About App':\n",
    "\n",
    "    st.markdown(\n",
    "        'In this application we are using **MediaPipe** from Google for creating a Movement Detection on a video')\n",
    "\n",
    "    st.text('**Djagora Team**')\n",
    "    st.markdown(\n",
    "        \"\"\"\n",
    "        <style>\n",
    "        [data-testid=\"stSidebar\"][aria-expanded=\"true\"] > div:first-child {\n",
    "            width: 350px;\n",
    "        }\n",
    "        [data-testid=\"stSidebar\"][aria-expanded=\"false\"] > div:first-chisld {\n",
    "            width: 350px;\n",
    "            margin-left: -350px;\n",
    "        }\n",
    "        </style>\n",
    "        \"\"\",\n",
    "        unsafe_allow_html=True,\n",
    "    )\n",
    "    st.image(\n",
    "        'https://scontent.ftun7-1.fna.fbcdn.net/v/t1.6435-9/117716527_305096250909701_5175488458046493683_n.png?_nc_cat=106&ccb=1-5&_nc_sid=e3f864&_nc_ohc=qozk54OdaM8AX8Go6fq&tn=Lf16wLVU8l36_cSv&_nc_ht=scontent.ftun7-1.fna&oh=6f73b59a15606ad45aef37b1dc7f3a4d&oe=61442316')\n",
    "\n",
    "elif app_mode == 'Run on Video':\n",
    "\n",
    "    st.subheader('We are applying Holonitic on a video')\n",
    "    st.set_option('deprecation.showfileUploaderEncoding', False)\n",
    "\n",
    "    use_webcam = st.sidebar.button('Use Webcam')\n",
    "    record = st.sidebar.checkbox(\"Record Video\")\n",
    "    if record:\n",
    "        st.checkbox(\"Recording\", value=True)\n",
    "        st.sidebar.text('Params For video')\n",
    "    st.markdown(\n",
    "        \"\"\"\n",
    "        <style>\n",
    "        [data-testid=\"stSidebar\"][aria-expanded=\"true\"] > div:first-child {\n",
    "            width: 400px;\n",
    "        }\n",
    "        [data-testid=\"stSidebar\"][aria-expanded=\"false\"] > div:first-child {\n",
    "            width: 400px;\n",
    "            margin-left: -400px;\n",
    "        }\n",
    "        </style>\n",
    "        \"\"\",\n",
    "        unsafe_allow_html=True,\n",
    "    )\n",
    "    detection_confidence = st.sidebar.slider('Min Detection Confidence', min_value=0.0, max_value=1.0, value=0.5)\n",
    "    tracking_confidence = st.sidebar.slider('Min Tracking Confidence', min_value=0.0, max_value=1.0, value=0.5)\n",
    "    st.sidebar.markdown('---')\n",
    "\n",
    "    st.markdown(' ## Output')\n",
    "    stframe = st.empty()\n",
    "    video_file_buffer = st.sidebar.file_uploader(\"Upload a video\", type=[\"mp4\", \"mov\", 'avi', 'asf', 'm4v'])\n",
    "    tfflie = tempfile.NamedTemporaryFile(delete=False)\n",
    "\n",
    "    if not video_file_buffer:\n",
    "        if use_webcam:\n",
    "            cap = cv2.VideoCapture(0)\n",
    "        else:\n",
    "            cap = cv2.VideoCapture(DEMO_VIDEO)\n",
    "            tfflie.name = DEMO_VIDEO\n",
    "\n",
    "    else:\n",
    "        tfflie.write(video_file_buffer.read())\n",
    "        cap = cv2.VideoCapture(tfflie.name)\n",
    "\n",
    "    st.sidebar.text('Input Video')\n",
    "    drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "\n",
    "    with mp_holistic.Holistic(\n",
    "            min_detection_confidence=detection_confidence,\n",
    "            min_tracking_confidence=tracking_confidence) as holistic:\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                continue\n",
    "\n",
    "            # Recolor Feed\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image.flags.writeable = True\n",
    "\n",
    "            # Make Detections\n",
    "            results = holistic.process(image)\n",
    "            # print(results.face_landmarks)\n",
    "\n",
    "            # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "\n",
    "            # Recolor image back to BGR for rendering\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            # 1. Draw face landmarks\n",
    "            mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS,\n",
    "                                      mp_drawing.DrawingSpec(color=(80, 110, 10), thickness=1, circle_radius=1),\n",
    "                                      mp_drawing.DrawingSpec(color=(80, 256, 121), thickness=1, circle_radius=1)\n",
    "                                      )\n",
    "\n",
    "            # 2. Right hand\n",
    "            mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                                      mp_drawing.DrawingSpec(color=(80, 22, 10), thickness=2, circle_radius=4),\n",
    "                                      mp_drawing.DrawingSpec(color=(80, 44, 121), thickness=2, circle_radius=2)\n",
    "                                      )\n",
    "            # 3. Left Hand\n",
    "            mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                                      mp_drawing.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4),\n",
    "                                      mp_drawing.DrawingSpec(color=(121, 44, 250), thickness=2, circle_radius=2)\n",
    "                                      )\n",
    "\n",
    "            # 4. Pose Detections\n",
    "            mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                                      mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=4),\n",
    "                                      mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "                                      )\n",
    "            # Export coordinates\n",
    "            try:\n",
    "                # Extract Pose landmarks\n",
    "                pose = results.pose_landmarks.landmark  # extraire tt les pts repere (pose)\n",
    "                pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in\n",
    "                                          pose]).flatten())  # extraire les diff coordonn√©es ds un tab numpy\n",
    "\n",
    "                # Extract Face landmarks\n",
    "                face = results.face_landmarks.landmark  # extraire tt les pts repere (face)\n",
    "                face_row = list(np.array(\n",
    "                    [[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in face]).flatten())\n",
    "                # face_row: maw face fiha x1  y1 z1 v1 kol wahda wahadha , fel face_row yet7Ato fard vect [x1 y1 z1 v1],[x2 y2 z2 v2]\n",
    "                # Concate rows\n",
    "                row = pose_row + face_row\n",
    "\n",
    "                # Append class name\n",
    "                # row.insert(0, class_name)\n",
    "\n",
    "                # Export to CSV\n",
    "                with open('coordonnees.csv', mode='a', newline='') as f:\n",
    "                    csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                    csv_writer.writerow(row)\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            image = cv2.resize(image, (0, 0), fx=0.8, fy=0.8)\n",
    "            image = image_resize(image=image, width=640)\n",
    "            stframe.image(image, channels='BGR', use_column_width=True)\n",
    "        cap.release()\n",
    "elif app_mode == 'Dataset':\n",
    "    st.map(csv_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfd3ad7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
